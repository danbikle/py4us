%h2 Class08 Answer:
%h2 Study syntax in the script.
%p I found a listing of the syntax at this URL:
%p
  %a(href='https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py' target='x')
    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py

%p As of today, 2017-07-23, the above script is 263 lines long.
%p I consider it readable and easy to understand.

%p An immediate problem I see at the top of the script is a very poor description:
.syntax
  %pre
    %code """Basic word2vec example."""

%p The author gave us 263 lines of syntax but only one line of description.

%p I interpret this to be a sign of laziness.

%p Near the top of the script I see this syntax:

.syntax
  %pre
    %code.python
      from __future__ import absolute_import
      from __future__ import division
      from __future__ import print_function

%p The above syntax is an attempt to make the script runnable from both Python2 and Python3.

%p
  %a(href='https://www.google.com/search?q=In+python+what+does+dunder+future+do?' target='x')
    https://www.google.com/search?q=In+python+what+does+dunder+future+do?

%p Next, I see some common imports:

.syntax
  %pre
    %code.python
      import collections
      import math
      import os
      import random
      import zipfile
      import numpy as np

%p Syntax which uses the collections-package appears twice, later in the script.

%p A URL to information about the collections-package is listed below:

%p
  %a(href='https://docs.python.org/3/library/collections.html' target='x')
    https://docs.python.org/3/library/collections.html
%p The collections-package gives me the collections.Counter() method.

%p I can use collections.Counter() to look for groups of numbers, or words, in a list.

%p For each group it finds, it will measure the group size.

%p I list a demo below:

.syntax
  %pre
    %code.python
      dan@a78:~/py4 $ python
      Python 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) 
      [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
      Type "help", "copyright", "credits" or "license" for more information.
      >>> import collections
      >>> collections.Counter([1,1,1,2,2,3])
      Counter({1: 3, 2: 2, 3: 1})
      >>> 

%p I can use collections.deque() to implement a queue:

.syntax
  %pre
    %code.python
      >>> my_q = collections.deque(maxlen=9)
      >>> my_q.extend([0])
      >>> my_q
      deque([0], maxlen=9)
      >>> my_q.extend([0,1])
      >>> my_q
      deque([0, 0, 1], maxlen=9)
      >>> my_q.extend([0,1,2])
      >>> my_q
      deque([0, 0, 1, 0, 1, 2], maxlen=9)
      >>> my_q.append(55)
      >>> my_q
      deque([0, 0, 1, 0, 1, 2, 55], maxlen=9)
      >>> my_q.appendleft(66)
      >>> my_q
      deque([66, 0, 0, 1, 0, 1, 2, 55], maxlen=9)
      >>> my_q.pop()
      55
      >>> my_q
      deque([66, 0, 0, 1, 0, 1, 2], maxlen=9)
      >>> my_q.popleft()
      66
      >>> my_q
      deque([0, 0, 1, 0, 1, 2], maxlen=9)
      >>> 

%p The author of word2vec_basic.py divides the script into 6 steps:

.syntax
  %pre
    =render 'class08syn1a'

%p The first step depends on the urllib package to download the file listed below:

%p
  %a(href='http://mattmahoney.net/dc/text8.zip' target='x')
    http://mattmahoney.net/dc/text8.zip

%p The downloaded file looks like this:

.syntax
  %pre
    =render 'class08syn1b'

%p The next step, Step 2, starts with a comment:
.syntax
  %pre
    %code.python # Step 2: Build the dictionary and replace rare words with UNK token.

%p An obvious question is then, "What is the dictionary?"

%p The next step, Step 2, depends on a function-call to build_dataset().

%p With the above question in mind, I studied inputs to the call and outputs of the call using pdb.set_trace():

.syntax
  %pre
    =render 'class08syn1c'

%p I can see above that build_dataset() is fed two inputs.
%p First is a list of 17,005,207 words called vocabulary.
%p Next is vocabulary_size which is 5,000 and might be intended to act as a cluster controller.
%p Perhaps the intent is to create 5,000 clusters of words.

%p Next, I studied a variable named, "data" which is the first output of build_dataset():

.syntax
  %pre
    =render 'class08syn1d'

%p It appears that "data" is a simple list of integers.  The length of the list is the same as the length of the list called: "vocabulary".

%p Since the two lists are the same length, I could match them element to element if I want.

%p Perhaps later, I will see why this list named "data" is useful.

%p Next, I studied a variable named, "count" which is the second output of build_dataset():

.syntax
  %pre
    =render 'class08syn1e'

%p I see that "count" is a simple list of 5,000 tuples.

%p Each tuple assigns an integer to word.

%p My guess is that each integer is a count of each word in vocabulary.

%p Based on that guess, perhaps the most frequent word is 'the' and it has appeared 1,061,396 times in vocabulary.

%p Next, I studied a variable named, "dictionary" which is the third output of build_dataset().
%p I assume this is the dictionary referred to in the Step-2-comment.

%p I studied "dictionary" while I had the debugger prompt:

.syntax
  %pre
    =render 'class08syn1f'

%hr/
%p
  %a(href='class08#lab')
    Class08
